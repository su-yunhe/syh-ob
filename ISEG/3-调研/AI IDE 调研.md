# 调研来源

- 2024 the 1st IDE Workshop, co-located with ICSE'24
	- https://ide-workshop.github.io/content/ide-2024.html
- 2025 the 2nd IDE Workshop, co-located with ICSE'25
	- https://ide-workshop.github.io/content/ide-2024.html
- China Open Source 2024 Annual Report
	- https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf
- Cursor 官网博客
	- https://www.cursor.com/cn/blog

# China Open Source 2024 Annual Report

## 一、2024年AI大模型如何影响基础软件行业中的「开发工具与环境」

### 1. AI编程的瓶颈
#### 1.1. 缺乏对领域知识的理解
比如 GitHub Copilot 对所有的编程语言用的都是一样的模型，甚至无法保证生成的这个编程语言的语法一定是正确的。 

#### 1.2. 缺乏对原生IDE的支持
因为时间关系，以前的 IDE 都没有预想到未来代码将由AI 生成，所以现在的 IDE 无法与AI 大模型进行一个高效的互操作，例如要修复 Copilot 的一个问题，我们需要一个接一个的串形进行修复，但大模型对算力的要求很高，会产生较大的延迟。

 **AI 代码生成需要更为宏观的看到工具链上的每一环**，包括：编程语言、集成开发环境（IDE）、 调试器、编译器和构建工具等。 但因为 Cursor 是一个做 IDE 的公司，它本身不拥有编程语言的服务，如果能**从编程语言开始自底向上的适配大模型，编程体验将会产生质的飞跃**。

### 2. AI 编程主要的机遇在于自底向上重构工具链
![[Pasted image 20250219150823.png]]

目前绝大多数编程语言诞生在 AI 大模型时代之前，也就是说此前很少有人认真设想过未来代码将由 AI 生产。几乎没有人**从底层考虑如何适配 AI 编程，建立一整套开发者工具包括编程语言、编译器、 调试工具、构建系统、静态分析安全检测工具等**。 特别是编程语言不仅要设计易于人类学习的编程语言，还要设计易于 AI 学习和生成代码。 以 Python 举例，它的优势是对于人类易读易学，动态类型系统减少了代码量，允许快速原型开发，增强了开发效率。但性能问题、内存消耗和多线程和并发处理确是它的劣势。 在 AI 大模型时代 Python 的优势不再明显，劣势却愈发变成挑战。优秀的智能编程助手不能仅关注行业大模型，AI 大模型对于「编程」只是冰山上的技术，**未来将是「开发工具和环境」与 AI 大模型高度整合平台的天下**。 

一个更加完善的 AI 编程场景：
- 通过思考语言设计和工具链适配，IDE 和工具链能够非常灵活地在当前的仓库检查、运行并更新 AI 大模型生成的代码块。
- IDE 内置的测试功能除了为程序员提供一种方便测试的机制以外，能够很好地在代码上下文 中作为相关代码的示例，从而大大提高代码生成及相关下游任务的正确性。 
- 除了在 IDE 中向用户提供常规的 AI 生成测试、撰写文档、修复错误等功能外，还能够提供完全后台运行的自动化智能体，**通过读取编译器的各项反馈**来完成各种相对复杂、长时间的下游任务，例如**提升测试覆盖率、从自然语言提示生成完整代码组件或者项目等**。

### 3. MoonBit

MoonBit（月兔）是从编程语言到集成开发环境（IDE）、调试器、编译器和构建工具等端到端编程语言工具链。

从顶层设计考虑如何让语言和工具 (IDE，调试器，静态分析，包管理等）一体化发展。从早期就构建了专属 MoonBit 的云端 IDE 和 AI 代码助手，并创新性的从底层构建之初就与 AI 大模型进行适配。

## 二、2024年AI编程技术与工具发展综述
### 1. AI IDE 现状

LLM生成代码采纳率不高，多数团队在 10% ～ 40% 之间。
![[Pasted image 20250219144532.png]]


AI编程助手使用现状：
![[Pasted image 20250219145207.png]]


在国内 AI编程开展比较好的大厂，超过 80%的工程师在使用 AI编程工具完成日常的编程工作，近 30%入库的代码由 AI生成，生成代码平均采纳率超过 40%，有些产品线达到 60%。仅仅在编程这一项工作（虽然只占开发人员 20-30%的工作量）上，研发效率能提升 20-30%。

### 2. 发展趋势总结
#### 2.1. 模型能力的基座能力增强： 
Claude 3 Opus、GPT-4o 、Claude 3.5 Sonnet、Claude 3.5 Haiku。

#### 2.2. 智能体（AI agent）的引进：
- 收集和学习与任务相关的知识
- 调用静态代码分析工具
- 调用搜索引擎和 API 为编程任务服务
- 通过构建代码仓库知识图来帮助大模型全面理解软件仓库的结构和依赖关系

例如从 RAG+GPT 4(1106)的 2.8%提升到 **SWE-agent+GPT 4(1106)** 的 22.4%、从 RAG+Claude 3 Opus 的 7%提升到 **SWE-agent+Claude 3 Opus**  的 18.2%，效果都比较显著。 

#### 2.3. 多模态能力：
能够综合利用视觉和文本信息，理解软件用户界面、 处理的图表、可视化数据、语法高亮和交互映射等内容。

目前排在 SWE-bench verified 前 4 位都使用了 **Claude-3.5-Sonnet**，是多模态的、具备处理文本和视觉信息的能力模型。 

#### 2.4. 工具集成的框架：
可以支持智能体在处理复杂任务时进行更好的任务管理和执行，并促进不同 AI 模型和工具之间的协作。 

- **Composio SWE-Kit** 集成文件操作、代码分析、Shell 命令执行、知识库管理和数据库操作等工具或能力，优势互补，将 SWE-bench verified 大幅度提升到 48.6%。
- **OpenHands+CodeAct v2.1** 将智能体的行为整合到统一代码行动空间的框架，允许 OpenHands 在编程任务中扮演全方位的智能助手角色，目前排在 SWE-bench verified第一位（53%）。

### 3. 未来展望
未来，研发人员和多个智能体、工具协同工作来完成编程工作，如论文 **Flows:Building Blocks of Reasoning and Collaborating AI** 所描述的，构成一个复合竞争性编码流程，研发人员更多是提需求，由 LLM 和智能体实现自主编程的过程。


![[Pasted image 20250219145051.png]]


> 该论文的主要目标是研究如何使用Flows框架来解决竞争编程问题（Competitive Coding）。通过将问题分解为结构化的推理、人类与AI的合作以及不同反馈类型下的迭代改进，Flows框架提供了有效的解决方案。例如，在竞争编程中，可以使用Plan Flow生成解决方案策略，然后使用Code Flow生成相应的代码。此外，还可以通过Human Flow在计划级别上集成人类，以提供自然语言中的短“计划”。最后，使用反思流和协作流等反馈机制，可以逐步改进解决方案并提高整体计算效率。

**ATDD（验收测试驱动开发）** 是大模型时代软件研发的正确打开方式。让大模型帮我们生成需求及其验收标准，业务约束更明确了，上下文更清楚了， 在此基础上分别由不同的模型生成产品代码和测试代码，再让它们之间相互验证和博弈（如图 4 所示），最终交付高质量的软件。

![[Pasted image 20250219145606.png]]


## 三、2024AI编程工具的进化

AI编程工具的形态：带扩展能力的IDE 插件、团队 AI 助手、结合 AI 的内部IM，以及作为基础能力的 Chatbot。

![[Pasted image 20250224102725.png]]
# Cursor官网博客

里面有一些对目前Cursor关注问题和研究进展的记录，具有启发性。
### 一、 Shadow Workspaces

Cursor 目前的工作：构建了一个“影子工作区”，让 AI 在不影响用户编码体验的情况下，在开发环境中迭代代码。
#### 1. 设计目标
1. **LSP-usability**：让AI 能够看到其更改的代码的lints（代码检查提示），并与语言服务器协议（LSP）进行交互（跳转到定义等）。
	- 就像人类开发者在编写代码时依赖实时提示来修正错误一样，AI能够通过LSP获取实时的代码检查结果（即“lints”），从而及时修正代码中的问题。
	- 通过LSP获取类型检查和符号信息，更好地理解代码的结构和语义。
2. **Runnability**：AI 能够运行其代码并查看输出。

这些目标需要在以下要求下实现：
1. **独立性**：用户的编码体验不受影响。
2. **隐私性**：用户的代码保持安全，所有操作都在本地进行。
3. **并发性**：多个 AI 可以同时工作。
4. **通用性**：适用于所有语言和工作区设置。
5. **可维护性**：代码尽量简洁，便于维护。
6. **速度**：操作延迟要短，能够处理数百个 AI 分支的吞吐量。

#### 2. 实现 LSP-usability
实现了一个隐藏的 Electron 窗口作为影子工作区。
当 AI 需要查看其代码的 lints 时，系统会生成一个隐藏窗口，AI 在该窗口中进行编辑并获取 lints，然后将结果返回给主窗口。这个隐藏窗口在不活动 15 分钟后会自动关闭，以减少内存占用。通过这种方式，AI 的操作完全独立于用户，不会影响用户的编码体验。
![[Pasted image 20250224100107.png]]

#### 3. 实现 Runnability
团队考虑了几种方法：
1. 简单复制；
2. 硬链接和符号链接；
3. 内核级文件夹代理。

#### 4. 未来发展方向
团队计划将影子工作区扩展到 Runnability，并解决在 macOS 和 Windows 上实现文件夹代理的挑战。他们还在考虑使用云环境来实现远程工作区，以减少用户的内存占用并确保完全独立。

### 二、Character Prefix Conditioning
介绍了一个名为“Character Prefix Conditioning”（字符前缀条件化）的算法，该算法旨在解决用语言模型进行代码补全时由于模型基于“token”而非字符级别操作，导致用户输入的字符不一定与模型的“token”边界对齐的问题，从而提高代码补全场景中生成答案的质量。

#### 1. 问题背景
大多数语言模型，如大语言模型（LLMs），在生成文本时是逐 token 进行的，而不是逐字符进行。可能会导致**用户输入的字符与 token 边界的不对齐**：如果用户输入的字符没有在 token 的边界上，直接将用户的输入转换为 token 并发送到模型会导致错误的结果。

#### 2. 解决思路
- **字符前缀条件化**：
	- 传统模型：next token依赖于前面的token
	- 新模型：next token依赖于前面的字符前缀 P

给定一个字符前缀 P，需要生成一个 token 序列 s = t1, t2, ..., tn，使得这些 token 的字符表示的连接（即 repr(t1) + repr(t2) + ... + repr(tn)）以 P 开头。
![[Pasted image 20250224104222.png]]

### 三、下一阶段关注的课题

这篇博客列举了Cursor目前关注攻关的4个课题。
#### 1. Next Action Prediction（下一步行动预测）

![[Pasted image 20250224002549.png]]

##### 1.1. 核心目标
预测开发者在编码过程中的下一步操作，包括按键、点击、编辑等低熵（low-entropy）动作，以实现低延迟的预测。
##### 1.2. 主要工作
- **扩展 Copilot++**：Cursor 的 Copilot++ 已经能够预测开发者下一步的编辑操作。团队希望进一步扩展这一功能，使其能够**预测开发者在编辑器中的所有操作，包括光标移动、文件切换、终端命令等**。
- **Cursor Flow**：通过预测开发者下一步的操作序列，实现一种流畅的编码体验。例如，**通过预测开发者会按 Tab 键 11 次和其他键 3 次，来实现自动补全和导航**。
- **多模态预测**：结合开发者的历史操作和上下文信息，预测开发者下一步可能的操作，如切换到的文件、运行的终端命令等。
##### 1.3. 研究方向
- **基础研究**：在代码库范围内进行动作预测的基础研究。
- **模型训练**：继续对 5-13B 参数的代码模型进行预训练和后训练，以实现低延迟的预测。
- **推理技巧**：采用类似于 Speculative Edits 的推理技巧，提高预测的准确性和效率。
- **用户体验**：设计非侵入式的方式，将预测的操作以友好的方式呈现给开发者。

#### 2. Perfect Edits（完美编辑）

##### 2.1. 核心目标
通过增加推理时间的计算资源，生成更高质量、更大规模的代码编辑，同时补偿由此带来的延迟。
##### 2.2. 主要工作
- **幻觉伪代码**：在后台执行代码编辑任务，确保开发者可以信任智能模型完成复杂的编辑操作。这样，用户实现不存在的函数/代码，然后模型在后台为我们创建它们。
- **多文件编辑**：对整个代码库进行通用编辑，例如一个准确跨越多个文件的编辑。
##### 2.3. 研究方向：
- **推理时间计算**：通过奖励模型和拒绝采样等方法，提高推理时间的计算效率。
- **更好的推理模型**：使用更先进的模型（如 GPT-5、Claude-4、Gemini 2.0）来提高代码生成的质量。
- **多语言服务器/文件系统副本**：为每个用户工作区运行多个语言服务器和文件系统副本，这需要模型具备工具使用能力和远程再现运行环境的能力。
- **模型性能训练**：通过训练和改进模型在代理轨迹上的性能，提高代码生成的准确性和效率。
- **用户体验实验**：进行大量的用户体验实验，以找到在流式异步编辑中最佳的呈现方式。

#### 3. Optimal Context（最优上下文）
##### 3.1. 核心目标
在处理大量文档、源代码、提交历史等信息时，找到最优的方式来整合和利用这些上下文信息，以解决单个查询。
##### 3.2. 主要工作
- **多模态信息整合**：整合文档、源代码、提交历史、UI 像素、生产日志、本地日志、Slack 消息等多模态信息，以提供更全面的上下文支持。
- **检索、递归和长上下文注意力**：使用检索、递归和长上下文注意力机制来处理这些信息，确保模型能够有效地利用所有相关数据。
##### 3.3. 研究方向
- **改进的嵌入和重排序器**：为代码库设计专门的嵌入和重排序器，以提高检索的准确性。
- **多跳嵌入训练**：训练多跳嵌入器，根据查询和已找到的相关代码，确定下一步需要跳转到的代码。
- **前缀缓存和自定义注意力掩码**：使用前缀缓存和自定义注意力掩码，以更好地适应代码库的结构。
- **代码库级别的检索研究**：进行代码库级别的检索研究，探索新的检索方法。
- **模型学习代码库**：训练模型在权重中学习代码库，类似于将变压器作为可微分的搜索索引。

#### 4. Bug Detection and Debugging（错误检测和调试）
##### 4.1. 核心目标
提高现有错误检测系统的准确性和代码库理解能力，减少误报，提高调试效率。
##### 4.2. 主要工作
- **AI 审查**：利用语言模型进行代码审查，尽管用户对误报的容忍度较高，但这需要改变用户的行为。
- **AI Linting**：开发一个始终运行的 linter，能够在后台捕获错误。这需要一个比 AI 审查更便宜、更快的模型，并且需要调低误报率。
- **智能调试**：超越基于 LLM 的静态分析，例如通过 `cursor/debug` 包在代码中注入调试信息，跟踪运行时信息，甚至在后台跟踪额外的变量状态。
##### 4.3. 研究方向
- **数据集策划和强化学习**：通过策划数据集（可能是合成数据）和在前沿代码模型上进行强化学习，提高模型的校准能力。
- **多源信息跟踪**：从其他表面（如浏览器或非集成终端）跟踪相关信息。
- **调试器特定工具使用**：提高模型在调试器特定工具使用和链式操作上的性能。
- **无限上下文和代码库理解**：实现无限上下文和近乎完美的代码库理解。
- **扩展 `cursor/debug` 库**：扩展 `cursor/debug` 库，以跟踪所有有用的程序状态信息。

# 2025 IDE WorkShop

## 一、Rethinking IDE Customization for Enhanced HAX: A Hyperdimensional Perspective

#### 摘要
随着集成开发环境（IDE）越来越多地融入人工智能，软件工程既面临诸如生产率提高等好处，也面临诸如用户偏好不匹配等挑战。我们提出**超维（HD）向量空间来建模人机交互，重点关注用户操作、风格偏好和项目背景**，以提升人机交互体验（Human-AI eXperiences, HAX）。

**行为序列预测**：通过将IDE记录的开发者动作序列转换成高维向量，并使用绑定和置换操作来编码时间顺序，从而实现对下一个动作的预测。 ![[Pasted image 20250224102107.png]]
![[Pasted image 20250224102038.png]]



**风格匹配**：通过将个人编程风格转换成高维向量，并将其与代码生成器的输出进行比较，从而实现在生成代码时保持一致的风格。
![[Pasted image 20250224102256.png]]

**项目上下文建模**：通过将项目相关的语言、API、设计模式等信息转换成高维向量，并在IDE中使用这些向量来提供更具体的建议和自动完成功能。
![[Pasted image 20250224102326.png]]



