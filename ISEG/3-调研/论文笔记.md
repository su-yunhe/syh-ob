# Automated Unit Test Improvement using Large Language Models at Meta

基于大模型的单元测试生成

![[Pasted image 20250430140340.png]]
这篇论文介绍了一种名为TestGen-LLM的工具，它使用大型语言模型（LLMs）自动改进现有的人类编写的测试代码。该工具通过验证其生成的测试类是否成功通过了一组过滤器来确保比原始测试套件有可衡量的改进，并消除了由于LLM幻觉而导致的问题。在Meta公司的Instagram和Facebook平台上进行了部署，在对Instagram的Reels和Stories产品进行评估时，TestGen-LLM的测试用例正确构建率为75％，可靠通过率为57％，覆盖率提高了25％。在Meta的Instagram和Facebook测试周中，TestGen-LLM对其应用的所有类中的11.5％进行了改进，其中73％的建议被Meta软件工程师接受并投入生产部署。这是工业规模部署由LLM生成的代码的第一个报告，并且有保证代码改进的支持。


# OPENRCA: CAN LARGE LANGUAGE MODELS LOCATE THE ROOT CAUSE OF SOFTWARE FAILURES?

![[Pasted image 20250430140550.png]]
这篇论文探讨了大型语言模型（LLM）在软件开发中的应用潜力，并提出了OpenRCA评估框架和基准数据集。该框架旨在评估LLM识别软件故障根本原因的能力，包括对软件依赖关系的理解和处理异构、长上下文的传感数据。实验结果表明，当前模型仅能解决最简单的情况，有很大的改进空间。因此，这项工作为未来的研究提供了方向。

# KalmanFormer: using transformer to model the Kalman Gain in Kalman Filters

![[Pasted image 20250430144750.png]]
本文介绍了一种新的状态估计算法——KalmanFormer。该算法将传统的卡尔曼滤波器与Transformer框架相结合，利用数据学习卡尔曼增益，从而更好地处理非线性系统和模型不匹配的情况。通过实验证明，KalmanFormer在跟踪隐藏状态方面的准确性优于经典的扩展卡尔曼滤波器，并具有更好的鲁棒性和精度。该算法对于信号处理中的动态系统状态估计任务具有重要的应用价值。



# SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering

![[Pasted image 20250430145634.png]]
这篇论文探讨了如何通过设计界面来提高语言模型代理（LM-agents）在软件工程任务中的表现。作者们提出了一个名为SWE-agent的系统，该系统为LM-agents提供了一个专门的代理计算机接口（ACI），使得它们能够自主地使用计算机解决软件工程问题。实验结果表明，SWE-agent在SWE-bench和HumanEvalFix上取得了最先进的性能，并且比非交互式LMs的表现要好得多。此外，作者还提供了关于ACI设计对代理行为和性能的影响的见解。
