# VM论文大纲

  论文：On the road to personalized code intelligence: Portraiting and Assisting Developers based on their in-IDE activities

虚拟替身：VirtualME

idea：软件开发智能化在完成一个task时，同哲学一样需要回答三个问题：

我是谁、我从哪来、要到哪去。

当前AI编程聚焦的问题是扩大静态代码上下文来解决代码生成等问题，即要到哪去，而少有人关注提问者本身，即我是谁、我从哪来这个问题。对应于该论文现程序员个人画像和行为追溯。

----------------------------------------------
## 一、论文大纲


1. 引言：从“代码智能”到“程序员智能”

• 现状：**大模型只关心“要到哪去”（生成/补全/修复），不关心“我是谁、从哪来”。**

• 提出假设：把 IDE 中每一次点击、滚动、调试、搜索、重构都视为“==数字指纹==”，即可还原一个可计算的“程序员本体”。

2. 定义behavior，加公式，定义artifact

3. VirtualME 架构、方法【核心】【遗留问题：数据底座如何展示】

A. 数据采集层
B. 用户画像层
C. 行为追溯层
D. 服务接口层to agent，MCP，怎么定义，prompt
– /ask_personal：个性化问答
– /fix_personal：缺陷修复建议

4. 实验场景 1+结果：个性化研发问答 （实验用于证明vm有作用，不用规模太大，尽量简单。10人，2x3，3种技术栈，2档熟练度:经验熟练度?~~仓库熟悉度?~~）设计+流程+探索问题+结果

  

• 问题：找能用到用户画像的问题(可以多一点)，贴近真实场景具备说服力。面对不熟悉的仓库。MCP提示词给出

• 指标：1. 证明画像正确；2. 个性化之后回答依然正确；3. 个性化指标(有无个性化diff) ，每个人不一样，增加了信息，信息熵等，老手的回答长度vs新手的回答长度，定量描述；展开这部分diff，个性化增加了哪些内容。参考METR的实验。4. 主观评价。5.不同LLM差异。token、推理耗时增加情况(理想情况差别不大)；使用多久产生的log可以稳定下来(画像不怎么变了)；

  

5. 实验场景 2+结果：行为相关缺陷修复。MCP提示词给出。自己就可以做。

注入bug：设计与行为有关的缺陷，错误操作/不当导致的bug 。1.行为无关bug；2. 行为敏感bug，各10-20条。LLM1能做对，2做不出。目标：缺陷定位+修复(尽量做到)。行为轨迹展示，2做对的log。不同LLM差异。token、推理耗时增加情况(理想情况差别不大)。回溯窗口的大小

  

6. discussion？超参、insight、threat、什么是个性化代码智能、前景(过程数据的优势)。MCP可以再加什么接口、犯错模式可分析。端侧模型+数据底座。新手变老手的过程，用户画像在其中的观察和指导作用，tool：web版IDE+vm or vm插件打包发布到market or 演示视频en

  

7. related works：MSR18, 丰富事件流…

  

8. 结论与展望

二期研发问答的改进方向

二期光标预测

缺陷修复

  

------------------------------------------------

## 二、亮点提炼

  

1. 首个把“IDE 行为全量日志”==转成可插拔的 Personal Embedding 的系统==。

2. 提出“==行为缺陷指纹==”概念——同样 bug，不同人犯错模式可区分。

3. 在隐私沙箱内完成训练-推理闭环，做到“数据不出本地，模型带走知识”。

4. 可解释 token 让 LLM 既能“用”个人记忆，又能“说”出为什么。

5. 两个场景均显示：当通用大模型束手无策时，个人画像可带来 30-40 % 绝对提升。

  

------------------------------------------------

## 三、关键概念

  

VirtualME

“程序员的数字孪生”，一段可更新的低维向量 + 一段可读的摘要文本，常驻本地，随用随取。

  

Personalized Embedding

把行为序列压缩到 512 维，时间衰减+注意力，保证“最近的我”权重最高。

  

Behavioral Bug Signature

根据调试轨迹、编辑序列、异常触发栈，聚类出“我容易犯的错”模板，用于缺陷定位。

  

Explainable Token

在 prompt 中插入形如 <ME:经常忘记判空> 的显式 token，既指导模型又让用户可审计。

  

------------------------------------------------

## 四、哲学映射

  

大多数 AI 编程：

“生成一段正确的代码”——只回答“要到哪去”。

  

VirtualME 的个性化编程：

“生成一段适合此刻的我、基于我的历史、解决我的痛点的代码”——同时回答

• 我是谁（个人画像）

• 我从哪来（IDE 行为轨迹）

• 要到哪去（任务目标）

  

------------------------------------------------

## 五、可继续脑洞的延伸方向

  

1. ~~团队级“群体画像”：VirtualME 的联邦聚合，做“谁最适合 review 这段代码”推荐。~~

2. 动态难度调节：根据认知负载实时降低 IDE 的提示噪声。

3. 终身学习：VirtualME 版本管理，支持“回滚到一周前的我”做 A/B。

4. 跨设备迁移：把 VirtualME 存进浏览器插件，Web IDE 也能识别“这是我”。